{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TV Script Generation\n",
    "In this project, you'll generate your own [Simpsons](https://en.wikipedia.org/wiki/The_Simpsons) TV scripts using RNNs.  You'll be using part of the [Simpsons dataset](https://www.kaggle.com/wcukierski/the-simpsons-by-the-data) of scripts from 27 seasons.  The Neural Network you'll build will generate a new TV script for a scene at [Moe's Tavern](https://simpsonswiki.com/wiki/Moe's_Tavern).\n",
    "## Get the Data\n",
    "The data is already provided for you.  You'll be using a subset of the original dataset.  It consists of only the scenes in Moe's Tavern.  This doesn't include other versions of the tavern, like \"Moe's Cavern\", \"Flaming Moe's\", \"Uncle Moe's Family Feed-Bag\", etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "\n",
    "data_dir = './data/simpsons/moes_tavern_lines.txt'\n",
    "text = helper.load_data(data_dir)\n",
    "# Ignore notice, since we don't use it for analysing the data\n",
    "text = text[81:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "Play around with `view_sentence_range` to view different parts of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 11492\n",
      "Number of scenes: 262\n",
      "Average number of sentences in each scene: 15.248091603053435\n",
      "Number of lines: 4257\n",
      "Average number of words in each line: 11.50434578341555\n",
      "\n",
      "The sentences 0 to 10:\n",
      "Moe_Szyslak: (INTO PHONE) Moe's Tavern. Where the elite meet to drink.\n",
      "Bart_Simpson: Eh, yeah, hello, is Mike there? Last name, Rotch.\n",
      "Moe_Szyslak: (INTO PHONE) Hold on, I'll check. (TO BARFLIES) Mike Rotch. Mike Rotch. Hey, has anybody seen Mike Rotch, lately?\n",
      "Moe_Szyslak: (INTO PHONE) Listen you little puke. One of these days I'm gonna catch you, and I'm gonna carve my name on your back with an ice pick.\n",
      "Moe_Szyslak: What's the matter Homer? You're not your normal effervescent self.\n",
      "Homer_Simpson: I got my problems, Moe. Give me another one.\n",
      "Moe_Szyslak: Homer, hey, you should not drink to forget your problems.\n",
      "Barney_Gumble: Yeah, you should only drink to enhance your social skills.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
    "scenes = text.split('\\n\\n')\n",
    "print('Number of scenes: {}'.format(len(scenes)))\n",
    "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
    "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
    "\n",
    "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
    "print('Number of lines: {}'.format(len(sentences)))\n",
    "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
    "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
    "\n",
    "print()\n",
    "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocessing Functions\n",
    "The first thing to do to any dataset is preprocessing.  Implement the following preprocessing functions below:\n",
    "- Lookup Table\n",
    "- Tokenize Punctuation\n",
    "\n",
    "### Lookup Table\n",
    "To create a word embedding, you first need to transform the words to ids.  In this function, create two dictionaries:\n",
    "- Dictionary to go from the words to an id, we'll call `vocab_to_int`\n",
    "- Dictionary to go from the id to word, we'll call `int_to_vocab`\n",
    "\n",
    "Return these dictionaries in the following tuple `(vocab_to_int, int_to_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "from collections import Counter \n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    :param text: The text of tv scripts split into words\n",
    "    :return: A tuple of dicts (vocab_to_int, int_to_vocab)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    vocab = Counter(text)\n",
    "    \n",
    "    vocab_to_int = { word: nr for nr, word in enumerate(vocab) }\n",
    "    int_to_vocab = { nr: word for word, nr in vocab_to_int.items() }\n",
    "    \n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_create_lookup_tables(create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Tokenize Punctuation\n",
    "We'll be splitting the script into a word array using spaces as delimiters.  However, punctuations like periods and exclamation marks make it hard for the neural network to distinguish between the word \"bye\" and \"bye!\".\n",
    "\n",
    "Implement the function `token_lookup` to return a dict that will be used to tokenize symbols like \"!\" into \"||Exclamation_Mark||\".  Create a dictionary for the following symbols where the symbol is the key and value is the token:\n",
    "- Period ( . )\n",
    "- Comma ( , )\n",
    "- Quotation Mark ( \" )\n",
    "- Semicolon ( ; )\n",
    "- Exclamation mark ( ! )\n",
    "- Question mark ( ? )\n",
    "- Left Parentheses ( ( )\n",
    "- Right Parentheses ( ) )\n",
    "- Dash ( -- )\n",
    "- Return ( \\n )\n",
    "\n",
    "This dictionary will be used to token the symbols and add the delimiter (space) around it.  This separates the symbols as it's own word, making it easier for the neural network to predict on the next word. Make sure you don't use a token that could be confused as a word. Instead of using the token \"dash\", try using something like \"||dash||\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def token_lookup():\n",
    "    \"\"\"\n",
    "    Generate a dict to turn punctuation into a token.\n",
    "    :return: Tokenize dictionary where the key is the punctuation and the value is the token\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return {\n",
    "        '.': \"||Period||\",\n",
    "        ',': \"||Comma||\",\n",
    "        '\"' : \"||Quotation_Mark||\",\n",
    "        ';' : \"||Semicolon||\",\n",
    "        '!' : \"||Exclamation_mark||\",\n",
    "        '?' : \"||Question_mark||\",\n",
    "        '(' : \"||Left_Parentheses||\",\n",
    "        ')' : \"||Right_Parentheses||\",\n",
    "        '--' : \"||Dash||\",\n",
    "        '\\n' : \"||Return||\"\n",
    "    }\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_tokenize(token_lookup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the data and save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint. If you ever decide to come back to this notebook or have to restart the notebook, you can start from here. The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import numpy as np\n",
    "import problem_unittests as tests\n",
    "\n",
    "int_text, vocab_to_int, int_to_vocab, token_dict = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the Neural Network\n",
    "You'll build the components necessary to build a RNN by implementing the following functions below:\n",
    "- get_inputs\n",
    "- get_init_cell\n",
    "- get_embed\n",
    "- build_rnn\n",
    "- build_nn\n",
    "- get_batches\n",
    "\n",
    "### Check the Version of TensorFlow and Access to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.1\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer'\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Input\n",
    "Implement the `get_inputs()` function to create TF Placeholders for the Neural Network.  It should create the following placeholders:\n",
    "- Input text placeholder named \"input\" using the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) `name` parameter.\n",
    "- Targets placeholder\n",
    "- Learning Rate placeholder\n",
    "\n",
    "Return the placeholders in the following the tuple `(Input, Targets, LearingRate)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name=\"input\")\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name=\"target\")\n",
    "    \n",
    "    learning_rate = tf.placeholder(tf.float32, name=\"learning_rate\")\n",
    "    \n",
    "    return inputs, targets, learning_rate\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_inputs(get_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN Cell and Initialize\n",
    "Stack one or more [`BasicLSTMCells`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicLSTMCell) in a [`MultiRNNCell`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell).\n",
    "- The Rnn size should be set using `rnn_size`\n",
    "- Initalize Cell State using the MultiRNNCell's [`zero_state()`](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/MultiRNNCell#zero_state) function\n",
    "    - Apply the name \"initial_state\" to the initial state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the cell and initial state in the following tuple `(Cell, InitialState)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_init_cell(batch_size, rnn_size):\n",
    "    \"\"\"\n",
    "    Create an RNN Cell and initialize it.\n",
    "    :param batch_size: Size of batches\n",
    "    :param rnn_size: Size of RNNs\n",
    "    :return: Tuple (cell, initialize state)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "\n",
    "    with tf.name_scope(\"lstm_layers\"):\n",
    "        cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "        cell = tf.contrib.rnn.MultiRNNCell([cell] * 2)\n",
    "\n",
    "    with tf.name_scope(\"lstm_initial_state\"):\n",
    "        initialState = cell.zero_state(batch_size, tf.float32)\n",
    "\n",
    "    initialState = tf.identity(initialState, \"initial_state\")\n",
    "\n",
    "    return cell, initialState\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_init_cell(get_init_cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Word Embedding\n",
    "Apply embedding to `input_data` using TensorFlow.  Return the embedded sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_embed(input_data, vocab_size, embed_dim):\n",
    "    \"\"\"\n",
    "    Create embedding for <input_data>.\n",
    "    :param input_data: TF placeholder for text input.\n",
    "    :param vocab_size: Number of words in vocabulary.\n",
    "    :param embed_dim: Number of embedding dimensions\n",
    "    :return: Embedded input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    with tf.name_scope(\"word_embedding\"):\n",
    "        embedding = tf.Variable(tf.random_uniform((vocab_size, embed_dim), -1, 1))\n",
    "        embed = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    return embed\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_embed(get_embed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build RNN\n",
    "You created a RNN Cell in the `get_init_cell()` function.  Time to use the cell to create a RNN.\n",
    "- Build the RNN using the [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)\n",
    " - Apply the name \"final_state\" to the final state using [`tf.identity()`](https://www.tensorflow.org/api_docs/python/tf/identity)\n",
    "\n",
    "Return the outputs and final_state state in the following tuple `(Outputs, FinalState)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_rnn(cell, inputs):\n",
    "    \"\"\"\n",
    "    Create a RNN using a RNN Cell\n",
    "    :param cell: RNN Cell\n",
    "    :param inputs: Input text data\n",
    "    :return: Tuple (Outputs, Final State)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    rnn, final_state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)\n",
    "    final_state = tf.identity(final_state, \"final_state\")\n",
    "    return rnn, final_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_rnn(build_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Neural Network\n",
    "Apply the functions you implemented above to:\n",
    "- Apply embedding to `input_data` using your `get_embed(input_data, vocab_size, embed_dim)` function.\n",
    "- Build RNN using `cell` and your `build_rnn(cell, inputs)` function.\n",
    "- Apply a fully connected layer with a linear activation and `vocab_size` as the number of outputs.\n",
    "\n",
    "Return the logits and final state in the following tuple (Logits, FinalState) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def build_nn(cell, rnn_size, input_data, vocab_size):\n",
    "    \"\"\"\n",
    "    Build part of the neural network\n",
    "    :param cell: RNN cell\n",
    "    :param rnn_size: Size of rnns\n",
    "    :param input_data: Input data\n",
    "    :param vocab_size: Vocabulary size\n",
    "    :return: Tuple (Logits, FinalState)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    embedding = get_embed(input_data, vocab_size, embed_dim=200)\n",
    "    output, final_state = build_rnn(cell, inputs=embedding)\n",
    "    fully_con = tf.contrib.layers.fully_connected(inputs=output, num_outputs=vocab_size, activation_fn=None)\n",
    "    \n",
    "    return fully_con, final_state\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_build_nn(build_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Batches\n",
    "Implement `get_batches` to create batches of input and targets using `int_text`.  The batches should be a Numpy array with the shape `(number of batches, 2, batch size, sequence length)`. Each batch contains two elements:\n",
    "- The first element is a single batch of **input** with the shape `[batch size, sequence length]`\n",
    "- The second element is a single batch of **targets** with the shape `[batch size, sequence length]`\n",
    "\n",
    "If you can't fill the last batch with enough data, drop the last batch.\n",
    "\n",
    "For exmple, `get_batches([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15], 2, 3)` would return a Numpy array of the following:\n",
    "```\n",
    "[\n",
    "  # First Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 1  2  3], [ 7  8  9]],\n",
    "    # Batch of targets\n",
    "    [[ 2  3  4], [ 8  9 10]]\n",
    "  ],\n",
    " \n",
    "  # Second Batch\n",
    "  [\n",
    "    # Batch of Input\n",
    "    [[ 4  5  6], [10 11 12]],\n",
    "    # Batch of targets\n",
    "    [[ 5  6  7], [11 12 13]]\n",
    "  ]\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def get_batches(int_text, batch_size, seq_length):\n",
    "    \"\"\"\n",
    "    Return batches of input and target\n",
    "    :param int_text: Text with the words replaced by their ids\n",
    "    :param batch_size: The size of batch\n",
    "    :param seq_length: The length of sequence\n",
    "    :return: Batches as a Numpy array\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    n_batches = int(len(int_text) / (batch_size * seq_length))\n",
    "\n",
    "    # Drop the last few characters to make only full batches\n",
    "    xdata = np.array(int_text[: n_batches * batch_size * seq_length])\n",
    "    ydata = np.array(int_text[1: n_batches * batch_size * seq_length + 1])\n",
    "\n",
    "    x_batches = np.split(xdata.reshape(batch_size, -1), n_batches, 1)\n",
    "    y_batches = np.split(ydata.reshape(batch_size, -1), n_batches, 1)\n",
    "    \n",
    "    #print(x_batches)\n",
    "    batches = np.array([x_batches, y_batches])\n",
    "    \n",
    "    return np.rot90(batches)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_get_batches(get_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "\n",
    "- Set `num_epochs` to the number of epochs.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `rnn_size` to the size of the RNNs.\n",
    "- Set `seq_length` to the length of sequence.\n",
    "- Set `learning_rate` to the learning rate.\n",
    "- Set `show_every_n_batches` to the number of batches the neural network should print progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nDON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Epochs\n",
    "num_epochs = [1]\n",
    "# Batch Size\n",
    "batch_size = [64, 128, 256]\n",
    "# RNN Size\n",
    "rnn_size = 256\n",
    "# Sequence Length\n",
    "seq_length = [50, 100, 150]\n",
    "# Learning Rate\n",
    "learning_rate = [0.005, 0.001, 0.0005]\n",
    "# Show stats for every n number of batches\n",
    "show_every_n_batches = 1\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "#save_dir = './save'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Build the Graph\n",
    "Build the graph using the neural network you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from tensorflow.contrib import seq2seq\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    vocab_size = len(int_to_vocab)\n",
    "    \n",
    "    with tf.name_scope(\"inputs\"):\n",
    "        input_text, targets, lr = get_inputs()\n",
    "        input_data_shape = tf.shape(input_text)\n",
    "        \n",
    "    with tf.name_scope(\"lstm\"):\n",
    "        cell, initial_state = get_init_cell(input_data_shape[0], rnn_size)\n",
    "    \n",
    "    with tf.name_scope(\"rnn_nn\"):\n",
    "        logits, final_state = build_nn(cell, rnn_size, input_text, vocab_size)\n",
    "\n",
    "    # Probabilities for generating words\n",
    "    \n",
    "    with tf.name_scope(\"activation\"):\n",
    "        probs = tf.nn.softmax(logits, name='probs')\n",
    "        tf.summary.histogram('predictions', probs)\n",
    "        \n",
    "    with tf.name_scope(\"back_propagation\"):\n",
    "        # Loss function\n",
    "        cost = seq2seq.sequence_loss(\n",
    "            logits,\n",
    "            targets,\n",
    "            tf.ones([input_data_shape[0], input_data_shape[1]]))\n",
    "        \n",
    "        tf.summary.scalar('cost', cost)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)\n",
    "    \n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train\n",
    "Train the neural network on the preprocessed data.  If you have a hard time getting a good loss, check the [forms](https://discussions.udacity.com/) to see if anyone is having the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5018 1171 2047 ..., 4500 1107 3950]\n",
      " [1037 1125 1614 ..., 1833  215 3898]\n",
      " [2183 1614 5559 ...,  215 1735 2844]\n",
      " ..., \n",
      " [ 215 3898  511 ..., 4924 5798 5733]\n",
      " [3422 2963 2465 ...,  319 2963 2712]\n",
      " [6545 4054 3493 ..., 3976 4652 5637]] [[1171 2047 3515 ..., 1107 3950 2157]\n",
      " [1125 1614 5324 ...,  215 3898 5815]\n",
      " [1614 5559  215 ..., 1735 2844 2193]\n",
      " ..., \n",
      " [3898  511 2171 ..., 5798 5733  215]\n",
      " [2963 2465  215 ..., 2963 2712 4494]\n",
      " [4054 3493 1901 ..., 4652 5637 5761]]\n",
      "[[6149 4039 3898 ...,  690 2995 3950]\n",
      " [4322 2899 5817 ..., 2465 4243 3466]\n",
      " [4243  712 4039 ...,  215  855 3468]\n",
      " ..., \n",
      " [3405 1614 6683 ..., 5015 3045 2339]\n",
      " [4162 1776 4587 ..., 4039 3898 1602]\n",
      " [3566 4746  686 ..., 5552 2963 4243]] [[4039 3898 5815 ..., 2995 3950 5018]\n",
      " [2899 5817 4924 ..., 4243 3466 1037]\n",
      " [ 712 4039 3898 ...,  855 3468 2183]\n",
      " ..., \n",
      " [1614 6683 3012 ..., 3045 2339  215]\n",
      " [1776 4587 2963 ..., 3898 1602 3422]\n",
      " [4746  686 1246 ..., 2963 4243 6545]]\n",
      "[[2891 3233 4039 ...,  829 2235 3688]\n",
      " [4134  108 5315 ..., 4243 1593 4773]\n",
      " [2086 2665  215 ..., 3468 4746  935]\n",
      " ..., \n",
      " [6484 2292 6402 ..., 6503 4039  108]\n",
      " [3898 5975 4243 ..., 4890   88 3298]\n",
      " [ 778 2339 1534 ..., 1279 1037 4163]] [[3233 4039 3898 ..., 2235 3688 6149]\n",
      " [ 108 5315 2379 ..., 1593 4773 4322]\n",
      " [2665  215 3239 ..., 4746  935 4243]\n",
      " ..., \n",
      " [2292 6402 5637 ..., 4039  108 3405]\n",
      " [5975 4243 6545 ...,   88 3298 4162]\n",
      " [2339 1534 2862 ..., 1037 4163 3566]]\n",
      "[[1549 1776 4337 ..., 2844 2235 3979]\n",
      " [ 676 5107 3114 ..., 5301 4022 5446]\n",
      " [1735 2171 5797 ..., 2086 4938 1171]\n",
      " ..., \n",
      " [5798 5452 4039 ..., 4620 2963 3979]\n",
      " [5815 2171 1289 ..., 4163 4746 4039]\n",
      " [2899 3757 4039 ..., 2862 4549  215]] [[1776 4337 4322 ..., 2235 3979 2891]\n",
      " [5107 3114 3850 ..., 4022 5446 4134]\n",
      " [2171 5797 1776 ..., 4938 1171 2086]\n",
      " ..., \n",
      " [5452 4039 3898 ..., 2963 3979 6484]\n",
      " [2171 1289 1776 ..., 4746 4039 3898]\n",
      " [3757 4039 3898 ..., 4549  215  778]]\n",
      "[[ 592 2803 2292 ..., 2171 3114  742]\n",
      " [4746 6522 5579 ..., 5326 1093  215]\n",
      " [1037 5821  215 ..., 3898 1914  215]\n",
      " ..., \n",
      " [ 511 5801  215 ..., 2963 3646 4596]\n",
      " [5905  942   32 ..., 1935  632 3898]\n",
      " [3898 3898 5975 ...,  215 3898 1602]] [[2803 2292  215 ..., 3114  742 1549]\n",
      " [6522 5579 3757 ..., 1093  215  676]\n",
      " [5821  215 2235 ..., 1914  215 1735]\n",
      " ..., \n",
      " [5801  215 3898 ..., 3646 4596 5798]\n",
      " [ 942   32 2768 ...,  632 3898 5815]\n",
      " [3898 5975 3087 ..., 3898 1602 2899]]\n",
      "[[6554 2963 3157 ..., 3401 6395 5637]\n",
      " [2193 4656 2047 ..., 5189 5882 5637]\n",
      " [2899 5589 2114 ..., 6395 5637 1086]\n",
      " ..., \n",
      " [ 215 1037 2106 ..., 5206 4039 3898]\n",
      " [3898 3898 3898 ..., 1171 1213 1037]\n",
      " [2868  215 5818 ..., 3336 1776 3898]] [[2963 3157 4039 ..., 6395 5637  592]\n",
      " [4656 2047 1171 ..., 5882 5637 4746]\n",
      " [5589 2114 4039 ..., 5637 1086 1037]\n",
      " ..., \n",
      " [1037 2106 3468 ..., 4039 3898  511]\n",
      " [3898 3898 4706 ..., 1213 1037 5905]\n",
      " [ 215 5818 1593 ..., 1776 3898 3898]]\n",
      "[[ 215 3898 5815 ..., 1776 4596 5798]\n",
      " [4587 1776 6552 ..., 1833 5633 3024]\n",
      " [ 215 1735 2171 ..., 2963 1493  778]\n",
      " ..., \n",
      " [1398  592 1614 ..., 2339 2963 4587]\n",
      " [3087 2963 2899 ..., 4887 1135 4039]\n",
      " [3198  632 3035 ..., 2963 4337 4322]] [[3898 5815 1037 ..., 4596 5798 6554]\n",
      " [1776 6552 5637 ..., 5633 3024 2193]\n",
      " [1735 2171 3114 ..., 1493  778 2899]\n",
      " ..., \n",
      " [ 592 1614 1717 ..., 2963 4587  215]\n",
      " [2963 2899  272 ..., 1135 4039 3898]\n",
      " [ 632 3035  108 ..., 4337 4322 2868]]\n",
      "[[ 215 3898 3898 ..., 2465 2963 6231]\n",
      " [4039 3898 1602 ..., 6309 2171 3114]\n",
      " [3505 4989 3505 ...,  632 3898 1914]\n",
      " ..., \n",
      " [5798 5868 2963 ...,  778 4234  215]\n",
      " [3694 4039 3898 ..., 3898 3898 1832]\n",
      " [4229 1776 1493 ..., 1776 2844 1043]] [[3898 3898 3898 ..., 2963 6231  215]\n",
      " [3898 1602 1534 ..., 2171 3114 4587]\n",
      " [4989 3505 1609 ..., 3898 1914  215]\n",
      " ..., \n",
      " [5868 2963 3694 ..., 4234  215 1398]\n",
      " [4039 3898 5943 ..., 3898 1832 3087]\n",
      " [1776 1493 4039 ..., 2844 1043 3198]]\n",
      "[[1033 1776 1875 ..., 3869  215  215]\n",
      " [4243 3566 2899 ...,  748 1752 3505]\n",
      " [4587 2963 3840 ..., 3257 1171 1178]\n",
      " ..., \n",
      " [ 215 3898 5815 ..., 2056 3950  930]\n",
      " [1037  215 3898 ..., 2499 6428 2963]\n",
      " [4039 5798 1400 ..., 1602 2171   88]] [[1776 1875 2868 ...,  215  215  215]\n",
      " [3566 2899 4426 ..., 1752 3505 4039]\n",
      " [2963 3840 1037 ..., 1171 1178 3505]\n",
      " ..., \n",
      " [3898 5815 2171 ..., 3950  930 5798]\n",
      " [ 215 3898 3898 ..., 6428 2963 3694]\n",
      " [5798 1400 3114 ..., 2171   88 4229]]\n",
      "[[4243 2748  108 ...,  215  215 2171]\n",
      " [2429 4746 5605 ..., 2260 2963 3646]\n",
      " [2171 1398 6015 ...,  742 2804 1776]\n",
      " ..., \n",
      " [2047  131 4590 ..., 5738 2679 1150]\n",
      " [1091 2963 6614 ...,  751 3925 6257]\n",
      " [3422  559 1236 ..., 1929 4243 2259]] [[2748  108 6231 ...,  215 2171 1033]\n",
      " [4746 5605 3455 ..., 2963 3646 4243]\n",
      " [1398 6015 1776 ..., 2804 1776 4587]\n",
      " ..., \n",
      " [ 131 4590 2963 ..., 2679 1150  215]\n",
      " [2963 6614  632 ..., 3925 6257 1037]\n",
      " [ 559 1236  215 ..., 4243 2259 4039]]\n",
      "[[ 215 4243 4557 ..., 2963  119 3493]\n",
      " [6427 4590 1833 ...,  748 3422 2963]\n",
      " [5175 1991  632 ..., 4039 3898 2075]\n",
      " ..., \n",
      " [4746 3439 5175 ...,  632 4243  789]\n",
      " [2963 2899  778 ..., 3898 3898 6422]\n",
      " [5785 3742 1776 ..., 3422 3885 2963]] [[4243 4557 3207 ...,  119 3493 4243]\n",
      " [4590 1833  215 ..., 3422 2963 2429]\n",
      " [1991  632 3898 ..., 3898 2075 2171]\n",
      " ..., \n",
      " [3439 5175 5059 ..., 4243  789 2047]\n",
      " [2899  778 6733 ..., 3898 6422 1091]\n",
      " [3742 1776 5736 ..., 3885 2963 3422]]\n",
      "[[1833 3637 3114 ...,  108  742 1240]\n",
      " [5917 1913 5798 ..., 2724 5152 1833]\n",
      " [1171 3383 5175 ...,  260  215 3238]\n",
      " ..., \n",
      " [3898 1602 3163 ..., 5798 2059 5406]\n",
      " [6617 5678 3840 ..., 3898  992 3198]\n",
      " [1037 2884 4177 ..., 2171 5882 4409]] [[3637 3114 1725 ...,  742 1240  215]\n",
      " [1913 5798 6233 ..., 5152 1833 6427]\n",
      " [3383 5175 3469 ...,  215 3238 5175]\n",
      " ..., \n",
      " [1602 3163 2963 ..., 2059 5406 4746]\n",
      " [5678 3840 2899 ...,  992 3198 2963]\n",
      " [2884 4177  215 ..., 5882 4409 5785]]\n",
      "[[4243 2765 5798 ..., 4184 1078 4322]\n",
      " [2963 6231 4039 ..., 5798  272 2899]\n",
      " [4243 2765 1534 ..., 3840  108  299]\n",
      " ..., \n",
      " [2106 5082 2780 ..., 1171 3310  215]\n",
      " [ 215 2086 3976 ..., 2963 4243 3233]\n",
      " [2765  108 2156 ..., 1776 3422 2963]] [[2765 5798 4061 ..., 1078 4322 1833]\n",
      " [6231 4039 5360 ...,  272 2899 5917]\n",
      " [2765 1534  456 ...,  108  299 1171]\n",
      " ..., \n",
      " [5082 2780  131 ..., 3310  215 3898]\n",
      " [2086 3976 5082 ..., 4243 3233 6617]\n",
      " [ 108 2156  215 ..., 3422 2963 1037]]\n",
      "[[3114 5997 2844 ..., 1764 5637 2963]\n",
      " [6427  215  215 ..., 1037 6333  131]\n",
      " [2963  407 4089 ..., 5700  215 4163]\n",
      " ..., \n",
      " [1833 3898  511 ..., 6503 2963 1037]\n",
      " [3025 3097  215 ..., 4322 5798 4678]\n",
      " [ 215 3898 5815 ..., 4275 2963 1037]] [[5997 2844 5579 ..., 5637 2963 4243]\n",
      " [ 215  215  215 ..., 6333  131 2963]\n",
      " [ 407 4089 3840 ...,  215 4163 4243]\n",
      " ..., \n",
      " [3898  511 2171 ..., 2963 1037 2106]\n",
      " [3097  215 1549 ..., 5798 4678  215]\n",
      " [3898 5815 2171 ..., 2963 1037 2765]]\n",
      "[[2963 1271  690 ..., 3840  108  616]\n",
      " [5175   64 5733 ...,   71  108 1833]\n",
      " [3515 3247 4131 ..., 1776 4620 5801]\n",
      " ..., \n",
      " [3625 3114 5884 ..., 1833 3979  215]\n",
      " [1960 2963 6093 ..., 6478 3149 1913]\n",
      " [3965 3522 1037 ..., 6089 6313 1833]] [[1271  690 2963 ...,  108  616 3114]\n",
      " [  64 5733  215 ...,  108 1833 6427]\n",
      " [3247 4131 5315 ..., 4620 5801 2963]\n",
      " ..., \n",
      " [3114 5884 2248 ..., 3979  215 1833]\n",
      " [2963 6093 4243 ..., 3149 1913 3025]\n",
      " [3522 1037 3609 ..., 6313 1833  215]]\n",
      "[[2963 4587  215 ..., 1392 3950 2193]\n",
      " [3950  215 3898 ...,  215 4243 5107]\n",
      " [5934 5388  215 ..., 3457 2292 3840]\n",
      " ..., \n",
      " [ 511 2171 3905 ...,  511 4243 6545]\n",
      " [5637 4177 5559 ..., 1549 1493 1468]\n",
      " [3510  215 1037 ...,  215  215  215]] [[4587  215  215 ..., 3950 2193 2963]\n",
      " [ 215 3898 1602 ..., 4243 5107 5175]\n",
      " [5388  215 3163 ..., 2292 3840 3515]\n",
      " ..., \n",
      " [2171 3905 1776 ..., 4243 6545 3625]\n",
      " [4177 5559 2963 ..., 1493 1468 1960]\n",
      " [ 215 1037 1593 ...,  215  215 3965]]\n",
      "[[5242 4039 3898 ..., 2963 5848 5621]\n",
      " [1833 4039 3898 ...,  215 5559  676]\n",
      " [3875  215 3898 ..., 6522 2354  108]\n",
      " ..., \n",
      " [3898  511 4243 ..., 2235  215 3898]\n",
      " [ 511 4587 2963 ..., 5253 4572 3059]\n",
      " [2963 5175 1837 ..., 2732  108 4789]] [[4039 3898 5815 ..., 5848 5621 2963]\n",
      " [4039 3898 5815 ..., 5559  676 3950]\n",
      " [ 215 3898 5815 ..., 2354  108 5934]\n",
      " ..., \n",
      " [ 511 4243  389 ...,  215 3898  511]\n",
      " [4587 2963 1771 ..., 4572 3059 5637]\n",
      " [5175 1837 2739 ...,  108 4789 3510]]\n",
      "[[3347 3979  248 ..., 3979 1645 2927]\n",
      " [ 215  215 3898 ..., 1833 6427  240]\n",
      " [ 215 5175 2806 ..., 3646 1220 1037]\n",
      " ..., \n",
      " [3030 3990  215 ..., 4746 4382  215]\n",
      " [4678  215 3898 ..., 3171  215 3898]\n",
      " [2963 6545  319 ..., 1931 2963 4587]] [[3979  248 4037 ..., 1645 2927 5242]\n",
      " [ 215 3898 1602 ..., 6427  240 1833]\n",
      " [5175 2806  778 ..., 1220 1037 3875]\n",
      " ..., \n",
      " [3990  215 3898 ..., 4382  215 3898]\n",
      " [ 215 3898 1602 ...,  215 3898  511]\n",
      " [6545  319  215 ..., 2963 4587 2963]]\n",
      "[[4596 5798 6554 ..., 5496 5459 3114]\n",
      " [4243 3930 3637 ..., 2292 4724  215]\n",
      " [5053  215 3850 ..., 2963 1220 1037]\n",
      " ..., \n",
      " [ 350 3114 5637 ..., 1776 2086 4572]\n",
      " [4740  215 3898 ..., 3114 5997 2899]\n",
      " [2963 5455  215 ..., 1194  215 4620]] [[5798 6554 6231 ..., 5459 3114 3347]\n",
      " [3930 3637 3114 ..., 4724  215  215]\n",
      " [ 215 3850 1442 ..., 1220 1037  215]\n",
      " ..., \n",
      " [3114 5637  215 ..., 2086 4572 3030]\n",
      " [ 215 3898 1602 ..., 5997 2899 4678]\n",
      " [5455  215 6219 ...,  215 4620 2963]]\n",
      "[[ 215  114 3414 ...,  215 3898 1602]\n",
      " [4422  433  215 ..., 2963 6231  215]\n",
      " [3823 5798 1502 ..., 5993 4563 5798]\n",
      " ..., \n",
      " [5360 2499 3596 ...,  119 6228 3493]\n",
      " [ 215 3898 1602 ..., 5637 4971  215]\n",
      " [ 108 4024 2356 ..., 5082 6004 1882]] [[ 114 3414  215 ..., 3898 1602 4596]\n",
      " [ 433  215 5798 ..., 6231  215 4243]\n",
      " [5798 1502 1917 ..., 4563 5798 5053]\n",
      " ..., \n",
      " [2499 3596 3114 ..., 6228 3493  350]\n",
      " [3898 1602 5480 ..., 4971  215 4740]\n",
      " [4024 2356 4322 ..., 6004 1882 2963]]\n",
      "[[1602 2171   88 ..., 1776  114 3414]\n",
      " [2157 3840  108 ..., 5616 4322 5175]\n",
      " [5815 3797  215 ..., 5262 2739 4243]\n",
      " ..., \n",
      " [ 215  215 1340 ..., 2585 6664 1776]\n",
      " [ 215 3571  696 ..., 1772 3422 6228]\n",
      " [4494 5833  215 ..., 1420 2339 3493]] [[2171   88 4229 ...,  114 3414  215]\n",
      " [3840  108 3488 ..., 4322 5175 4422]\n",
      " [3797  215 3406 ..., 2739 4243 3823]\n",
      " ..., \n",
      " [ 215 1340  215 ..., 6664 1776 5360]\n",
      " [3571  696  215 ..., 3422 6228  215]\n",
      " [5833  215 3898 ..., 2339 3493  108]]\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(int_text, batch_size[0], seq_length[0])\n",
    "for batch_i, (x, y) in enumerate(batches):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "!rm -r tensorboard/*\n",
    "!rm -r trained_models/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 64 50 0.005\n",
      "Epoch   0 Batch    0/21   train_loss = 8.821\n",
      "Epoch   0 Batch    1/21   train_loss = 8.727\n",
      "Epoch   0 Batch    2/21   train_loss = 7.924\n",
      "Epoch   0 Batch    3/21   train_loss = 7.116\n",
      "Epoch   0 Batch    4/21   train_loss = 6.566\n",
      "Epoch   0 Batch    5/21   train_loss = 6.349\n",
      "Epoch   0 Batch    6/21   train_loss = 6.242\n",
      "Epoch   0 Batch    7/21   train_loss = 6.384\n",
      "Epoch   0 Batch    8/21   train_loss = 6.682\n",
      "Epoch   0 Batch    9/21   train_loss = 6.609\n",
      "Epoch   0 Batch   10/21   train_loss = 6.607\n",
      "Epoch   0 Batch   11/21   train_loss = 6.546\n",
      "Epoch   0 Batch   12/21   train_loss = 6.477\n",
      "Epoch   0 Batch   13/21   train_loss = 6.524\n",
      "Epoch   0 Batch   14/21   train_loss = 6.703\n",
      "Epoch   0 Batch   15/21   train_loss = 6.567\n",
      "Epoch   0 Batch   16/21   train_loss = 6.584\n",
      "Epoch   0 Batch   17/21   train_loss = 6.604\n",
      "Epoch   0 Batch   18/21   train_loss = 6.503\n",
      "Epoch   0 Batch   19/21   train_loss = 6.495\n",
      "Epoch   0 Batch   20/21   train_loss = 6.512\n",
      "1 64 50 0.001\n",
      "Epoch   0 Batch    0/21   train_loss = 8.822\n",
      "Epoch   0 Batch    1/21   train_loss = 8.804\n",
      "Epoch   0 Batch    2/21   train_loss = 8.765\n",
      "Epoch   0 Batch    3/21   train_loss = 8.654\n",
      "Epoch   0 Batch    4/21   train_loss = 8.469\n",
      "Epoch   0 Batch    5/21   train_loss = 8.239\n",
      "Epoch   0 Batch    6/21   train_loss = 7.961\n",
      "Epoch   0 Batch    7/21   train_loss = 7.678\n",
      "Epoch   0 Batch    8/21   train_loss = 7.474\n",
      "Epoch   0 Batch    9/21   train_loss = 7.163\n",
      "Epoch   0 Batch   10/21   train_loss = 6.957\n",
      "Epoch   0 Batch   11/21   train_loss = 6.754\n",
      "Epoch   0 Batch   12/21   train_loss = 6.551\n",
      "Epoch   0 Batch   13/21   train_loss = 6.431\n",
      "Epoch   0 Batch   14/21   train_loss = 6.415\n",
      "Epoch   0 Batch   15/21   train_loss = 6.305\n",
      "Epoch   0 Batch   16/21   train_loss = 6.216\n",
      "Epoch   0 Batch   17/21   train_loss = 6.188\n",
      "Epoch   0 Batch   18/21   train_loss = 6.172\n",
      "Epoch   0 Batch   19/21   train_loss = 6.151\n",
      "Epoch   0 Batch   20/21   train_loss = 6.179\n",
      "1 64 50 0.0005\n",
      "Epoch   0 Batch    0/21   train_loss = 8.822\n",
      "Epoch   0 Batch    1/21   train_loss = 8.814\n",
      "Epoch   0 Batch    2/21   train_loss = 8.804\n",
      "Epoch   0 Batch    3/21   train_loss = 8.789\n",
      "Epoch   0 Batch    4/21   train_loss = 8.759\n",
      "Epoch   0 Batch    5/21   train_loss = 8.716\n",
      "Epoch   0 Batch    6/21   train_loss = 8.634\n",
      "Epoch   0 Batch    7/21   train_loss = 8.526\n",
      "Epoch   0 Batch    8/21   train_loss = 8.434\n",
      "Epoch   0 Batch    9/21   train_loss = 8.287\n",
      "Epoch   0 Batch   10/21   train_loss = 8.149\n",
      "Epoch   0 Batch   11/21   train_loss = 8.011\n",
      "Epoch   0 Batch   12/21   train_loss = 7.849\n",
      "Epoch   0 Batch   13/21   train_loss = 7.700\n",
      "Epoch   0 Batch   14/21   train_loss = 7.592\n",
      "Epoch   0 Batch   15/21   train_loss = 7.405\n",
      "Epoch   0 Batch   16/21   train_loss = 7.249\n",
      "Epoch   0 Batch   17/21   train_loss = 7.109\n",
      "Epoch   0 Batch   18/21   train_loss = 6.967\n",
      "Epoch   0 Batch   19/21   train_loss = 6.842\n",
      "Epoch   0 Batch   20/21   train_loss = 6.730\n",
      "1 64 100 0.005\n",
      "Epoch   0 Batch    0/10   train_loss = 8.823\n",
      "Epoch   0 Batch    1/10   train_loss = 8.773\n",
      "Epoch   0 Batch    2/10   train_loss = 8.031\n",
      "Epoch   0 Batch    3/10   train_loss = 7.223\n",
      "Epoch   0 Batch    4/10   train_loss = 6.593\n",
      "Epoch   0 Batch    5/10   train_loss = 6.250\n",
      "Epoch   0 Batch    6/10   train_loss = 6.210\n",
      "Epoch   0 Batch    7/10   train_loss = 6.343\n",
      "Epoch   0 Batch    8/10   train_loss = 6.521\n",
      "Epoch   0 Batch    9/10   train_loss = 6.640\n",
      "1 64 100 0.001\n",
      "Epoch   0 Batch    0/10   train_loss = 8.822\n",
      "Epoch   0 Batch    1/10   train_loss = 8.802\n",
      "Epoch   0 Batch    2/10   train_loss = 8.760\n",
      "Epoch   0 Batch    3/10   train_loss = 8.638\n",
      "Epoch   0 Batch    4/10   train_loss = 8.416\n",
      "Epoch   0 Batch    5/10   train_loss = 8.152\n",
      "Epoch   0 Batch    6/10   train_loss = 7.916\n",
      "Epoch   0 Batch    7/10   train_loss = 7.644\n",
      "Epoch   0 Batch    8/10   train_loss = 7.367\n",
      "Epoch   0 Batch    9/10   train_loss = 7.135\n",
      "1 64 100 0.0005\n",
      "Epoch   0 Batch    0/10   train_loss = 8.822\n",
      "Epoch   0 Batch    1/10   train_loss = 8.812\n",
      "Epoch   0 Batch    2/10   train_loss = 8.798\n",
      "Epoch   0 Batch    3/10   train_loss = 8.776\n",
      "Epoch   0 Batch    4/10   train_loss = 8.729\n",
      "Epoch   0 Batch    5/10   train_loss = 8.640\n",
      "Epoch   0 Batch    6/10   train_loss = 8.535\n",
      "Epoch   0 Batch    7/10   train_loss = 8.397\n",
      "Epoch   0 Batch    8/10   train_loss = 8.251\n",
      "Epoch   0 Batch    9/10   train_loss = 8.118\n",
      "1 64 150 0.005\n",
      "Epoch   0 Batch    0/7   train_loss = 8.822\n",
      "Epoch   0 Batch    1/7   train_loss = 8.733\n",
      "Epoch   0 Batch    2/7   train_loss = 7.879\n",
      "Epoch   0 Batch    3/7   train_loss = 7.111\n",
      "Epoch   0 Batch    4/7   train_loss = 6.515\n",
      "Epoch   0 Batch    5/7   train_loss = 6.252\n",
      "Epoch   0 Batch    6/7   train_loss = 6.205\n",
      "1 64 150 0.001\n",
      "Epoch   0 Batch    0/7   train_loss = 8.820\n",
      "Epoch   0 Batch    1/7   train_loss = 8.797\n",
      "Epoch   0 Batch    2/7   train_loss = 8.734\n",
      "Epoch   0 Batch    3/7   train_loss = 8.576\n",
      "Epoch   0 Batch    4/7   train_loss = 8.329\n",
      "Epoch   0 Batch    5/7   train_loss = 8.061\n",
      "Epoch   0 Batch    6/7   train_loss = 7.781\n",
      "1 64 150 0.0005\n",
      "Epoch   0 Batch    0/7   train_loss = 8.823\n",
      "Epoch   0 Batch    1/7   train_loss = 8.814\n",
      "Epoch   0 Batch    2/7   train_loss = 8.801\n",
      "Epoch   0 Batch    3/7   train_loss = 8.780\n",
      "Epoch   0 Batch    4/7   train_loss = 8.735\n",
      "Epoch   0 Batch    5/7   train_loss = 8.659\n",
      "Epoch   0 Batch    6/7   train_loss = 8.547\n",
      "1 128 50 0.005\n",
      "Epoch   0 Batch    0/10   train_loss = 8.822\n",
      "Epoch   0 Batch    1/10   train_loss = 8.759\n",
      "Epoch   0 Batch    2/10   train_loss = 7.970\n",
      "Epoch   0 Batch    3/10   train_loss = 7.235\n",
      "Epoch   0 Batch    4/10   train_loss = 6.588\n",
      "Epoch   0 Batch    5/10   train_loss = 6.274\n",
      "Epoch   0 Batch    6/10   train_loss = 6.306\n",
      "Epoch   0 Batch    7/10   train_loss = 6.399\n",
      "Epoch   0 Batch    8/10   train_loss = 6.560\n",
      "Epoch   0 Batch    9/10   train_loss = 6.628\n",
      "1 128 50 0.001\n",
      "Epoch   0 Batch    0/10   train_loss = 8.822\n",
      "Epoch   0 Batch    1/10   train_loss = 8.800\n",
      "Epoch   0 Batch    2/10   train_loss = 8.750\n",
      "Epoch   0 Batch    3/10   train_loss = 8.628\n",
      "Epoch   0 Batch    4/10   train_loss = 8.417\n",
      "Epoch   0 Batch    5/10   train_loss = 8.155\n",
      "Epoch   0 Batch    6/10   train_loss = 7.909\n",
      "Epoch   0 Batch    7/10   train_loss = 7.611\n",
      "Epoch   0 Batch    8/10   train_loss = 7.360\n",
      "Epoch   0 Batch    9/10   train_loss = 7.116\n",
      "1 128 50 0.0005\n",
      "Epoch   0 Batch    0/10   train_loss = 8.822\n",
      "Epoch   0 Batch    1/10   train_loss = 8.813\n",
      "Epoch   0 Batch    2/10   train_loss = 8.799\n",
      "Epoch   0 Batch    3/10   train_loss = 8.779\n",
      "Epoch   0 Batch    4/10   train_loss = 8.743\n",
      "Epoch   0 Batch    5/10   train_loss = 8.674\n",
      "Epoch   0 Batch    6/10   train_loss = 8.585\n",
      "Epoch   0 Batch    7/10   train_loss = 8.450\n",
      "Epoch   0 Batch    8/10   train_loss = 8.327\n",
      "Epoch   0 Batch    9/10   train_loss = 8.189\n",
      "1 128 100 0.005\n",
      "Epoch   0 Batch    0/5   train_loss = 8.820\n",
      "Epoch   0 Batch    1/5   train_loss = 8.650\n",
      "Epoch   0 Batch    2/5   train_loss = 7.679\n",
      "Epoch   0 Batch    3/5   train_loss = 6.926\n",
      "Epoch   0 Batch    4/5   train_loss = 6.436\n",
      "1 128 100 0.001\n",
      "Epoch   0 Batch    0/5   train_loss = 8.821\n",
      "Epoch   0 Batch    1/5   train_loss = 8.800\n",
      "Epoch   0 Batch    2/5   train_loss = 8.743\n",
      "Epoch   0 Batch    3/5   train_loss = 8.594\n",
      "Epoch   0 Batch    4/5   train_loss = 8.359\n",
      "1 128 100 0.0005\n",
      "Epoch   0 Batch    0/5   train_loss = 8.823\n",
      "Epoch   0 Batch    1/5   train_loss = 8.813\n",
      "Epoch   0 Batch    2/5   train_loss = 8.801\n",
      "Epoch   0 Batch    3/5   train_loss = 8.780\n",
      "Epoch   0 Batch    4/5   train_loss = 8.745\n",
      "1 128 150 0.005\n",
      "Epoch   0 Batch    0/3   train_loss = 8.822\n",
      "Epoch   0 Batch    1/3   train_loss = 8.726\n",
      "Epoch   0 Batch    2/3   train_loss = 7.839\n",
      "1 128 150 0.001\n",
      "Epoch   0 Batch    0/3   train_loss = 8.822\n",
      "Epoch   0 Batch    1/3   train_loss = 8.802\n",
      "Epoch   0 Batch    2/3   train_loss = 8.752\n",
      "1 128 150 0.0005\n",
      "Epoch   0 Batch    0/3   train_loss = 8.822\n",
      "Epoch   0 Batch    1/3   train_loss = 8.811\n",
      "Epoch   0 Batch    2/3   train_loss = 8.797\n",
      "1 256 50 0.005\n",
      "Epoch   0 Batch    0/5   train_loss = 8.822\n",
      "Epoch   0 Batch    1/5   train_loss = 8.736\n",
      "Epoch   0 Batch    2/5   train_loss = 7.898\n",
      "Epoch   0 Batch    3/5   train_loss = 7.177\n",
      "Epoch   0 Batch    4/5   train_loss = 6.589\n",
      "1 256 50 0.001\n",
      "Epoch   0 Batch    0/5   train_loss = 8.822\n",
      "Epoch   0 Batch    1/5   train_loss = 8.802\n",
      "Epoch   0 Batch    2/5   train_loss = 8.753\n",
      "Epoch   0 Batch    3/5   train_loss = 8.636\n",
      "Epoch   0 Batch    4/5   train_loss = 8.439\n",
      "1 256 50 0.0005\n",
      "Epoch   0 Batch    0/5   train_loss = 8.822\n",
      "Epoch   0 Batch    1/5   train_loss = 8.812\n",
      "Epoch   0 Batch    2/5   train_loss = 8.799\n",
      "Epoch   0 Batch    3/5   train_loss = 8.780\n",
      "Epoch   0 Batch    4/5   train_loss = 8.742\n",
      "1 256 100 0.005\n",
      "Epoch   0 Batch    0/2   train_loss = 8.823\n",
      "Epoch   0 Batch    1/2   train_loss = 8.741\n",
      "1 256 100 0.001\n",
      "Epoch   0 Batch    0/2   train_loss = 8.820\n",
      "Epoch   0 Batch    1/2   train_loss = 8.798\n",
      "1 256 100 0.0005\n",
      "Epoch   0 Batch    0/2   train_loss = 8.822\n",
      "Epoch   0 Batch    1/2   train_loss = 8.811\n",
      "1 256 150 0.005\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[38400,6779]\n\t [[Node: activation/probs = Softmax[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](activation/Reshape)]]\n\t [[Node: activation/Reshape_1/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1365_activation/Reshape_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'activation/probs', defined at:\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-974a7722cd30>\", line 23, in <module>\n    probs = tf.nn.softmax(logits, name='probs')\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 1502, in softmax\n    return _softmax(logits, gen_nn_ops._softmax, dim, name)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 1453, in _softmax\n    output = compute_op(logits, name=name)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2234, in _softmax\n    result = _op_def_lib.apply_op(\"Softmax\", logits=logits, name=name)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[38400,6779]\n\t [[Node: activation/probs = Softmax[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](activation/Reshape)]]\n\t [[Node: activation/Reshape_1/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1365_activation/Reshape_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[38400,6779]\n\t [[Node: activation/probs = Softmax[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](activation/Reshape)]]\n\t [[Node: activation/Reshape_1/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1365_activation/Reshape_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-554075bee4f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mlearning__rate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum__epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch__size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq__length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning__rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum__epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch__size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq__length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning__rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'All Model Trained and Saved'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-554075bee4f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, batch_size, seq_length, learning_rate)\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0minitial_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                     lr: learning_rate}\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmerged\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Show every <show_every_n_batches> batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[38400,6779]\n\t [[Node: activation/probs = Softmax[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](activation/Reshape)]]\n\t [[Node: activation/Reshape_1/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1365_activation/Reshape_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'activation/probs', defined at:\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-14-974a7722cd30>\", line 23, in <module>\n    probs = tf.nn.softmax(logits, name='probs')\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 1502, in softmax\n    return _softmax(logits, gen_nn_ops._softmax, dim, name)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 1453, in _softmax\n    output = compute_op(logits, name=name)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2234, in _softmax\n    result = _op_def_lib.apply_op(\"Softmax\", logits=logits, name=name)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/benjamin/anaconda3/envs/dl/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[38400,6779]\n\t [[Node: activation/probs = Softmax[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](activation/Reshape)]]\n\t [[Node: activation/Reshape_1/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1365_activation/Reshape_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "def train(num_epochs, batch_size, seq_length, learning_rate):\n",
    "    batches = get_batches(int_text, batch_size, seq_length)\n",
    "    \n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "\n",
    "    with tf.Session(graph=train_graph, config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        file_writer = tf.summary.FileWriter(\"./tensorboard/lr={},bs={},sl={}\".format(learning_rate, batch_size, seq_length), sess.graph)\n",
    "        iteration = 0\n",
    "\n",
    "        for epoch_i in range(num_epochs):\n",
    "            state = sess.run(initial_state, {input_text: batches[0][0]})\n",
    "\n",
    "            for batch_i, (x, y) in enumerate(batches):\n",
    "                feed = {\n",
    "                    input_text: x,\n",
    "                    targets: y,\n",
    "                    initial_state: state,\n",
    "                    lr: learning_rate}\n",
    "                summary, train_loss, state, _ = sess.run([merged, cost, final_state, train_op], feed)\n",
    "\n",
    "                # Show every <show_every_n_batches> batches\n",
    "                if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
    "                    print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
    "                        epoch_i,\n",
    "                        batch_i,\n",
    "                        len(batches),\n",
    "                        train_loss))\n",
    "\n",
    "                file_writer.add_summary(summary, iteration)\n",
    "                iteration += 1\n",
    "\n",
    "        # Save Model\n",
    "        folder = \"./trained_models/lr={},bs={},sl={}/model\".format(learning_rate, batch_size, seq_length)\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, folder)\n",
    "\n",
    "for num__epochs in num_epochs:\n",
    "    for batch__size in batch_size:\n",
    "        for seq__length in seq_length:\n",
    "            for learning__rate in learning_rate:\n",
    "                print(num__epochs, batch__size, seq__length, learning__rate)\n",
    "                train(num__epochs, batch__size, seq__length, learning__rate)\n",
    "        \n",
    "print('All Model Trained and Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}